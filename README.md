ğŸ“Š Fortune-500 Dashboard

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![MySQL](https://img.shields.io/badge/Database-MySQL-orange)
![Dash](https://img.shields.io/badge/Dashboard-Plotly%20Dash-purple)
![Selenium](https://img.shields.io/badge/Scraper-Selenium-brightgreen)


ğŸ” Overview

The Fortune-500 Dashboard is a complete pipeline that:

Scrapes the latest Fortune 500 company data

Stores it in a MySQL database

Visualizes insights in an interactive dashboard built with Dash

Itâ€™s designed for automation, analysis, and visualization of company trends like revenue, ranking, and industries.

ğŸš€ Key Features

âœ… Automated scraping of company details (name, revenue, rank, industry, etc.)
âœ… Structured storage in MySQL database
âœ… Scheduler to run scraping jobs periodically
âœ… Interactive dashboard with graphs, charts & filters
âœ… Export data to CSV / Excel
âœ… Secure setup with .env for credentials
âœ… Built-in logging & alerts for scraper runs

ğŸ“‚ Project Structure
### Project Structure
 
â”‚â”€â”€ style.css # CSS and frontend assets (if any)
â”‚
â”‚â”€â”€ api.py # API or scraping logic
â”‚â”€â”€ csvfileconversion.py # CSV/Excel conversion utilities
â”‚â”€â”€ final.py # Main processing script
â”‚â”€â”€ log changes.py # Logs / changes tracking
â”‚â”€â”€ logging system.py # Logging utilities
â”‚â”€â”€ main.py # Main program
â”‚â”€â”€ normalization.py # Data normalization utilities
â”‚â”€â”€ run.py # Entry point (scheduler + scraper)
â”‚â”€â”€ .env.example # Example environment variables
â”‚â”€â”€ requirements.txt # Python dependencies


ğŸ› ï¸ Tech Stack

Python 3.10+

Selenium â†’ Web scraping

MySQL â†’ Database storage

Dash / Plotly â†’ Interactive dashboard

APScheduler â†’ Task scheduling

pandas â†’ Data manipulation

âš¡ Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/MitaliSwamy/Fortune-500-Dashboard.git
cd Fortune-500-Dashboard

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Configure .env

Create a .env file in the project root with your database and email credentials (see .env.example).

4ï¸âƒ£ Run the project
python run.py

ğŸ“ Notes

Ensure your MySQL server is running and accessible.

Adjust scraping intervals in run.py as needed.

Email alerts will be sent on scraper failure (configured in .env).
